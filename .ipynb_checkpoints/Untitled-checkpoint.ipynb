{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import random as rm\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csr_read(fname, ftype=\"csr\", nidx=1):\n",
    "    r\"\"\" \n",
    "        Read CSR matrix from a text file. \n",
    "        \n",
    "        \\param fname File name for CSR/CLU matrix\n",
    "        \\param ftype Input format. Acceptable formats are:\n",
    "            - csr - Compressed sparse row\n",
    "            - clu - Cluto format, i.e., CSR + header row with \"nrows ncols nnz\"\n",
    "        \\param nidx Indexing type in CSR file. What does numbering of feature IDs start with?\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    if ftype == \"clu\":\n",
    "        p = lines[0].split()\n",
    "        nrows = int(p[0])\n",
    "        ncols = int(p[1])\n",
    "        nnz = long(p[2])\n",
    "        lines = lines[1:]\n",
    "        assert(len(lines) == nrows)\n",
    "    elif ftype == \"csr\":\n",
    "        nrows = len(lines)\n",
    "        ncols = 0 \n",
    "        nnz = 0 \n",
    "        for i in xrange(nrows):\n",
    "            p = lines[i].split()\n",
    "            if len(p) % 2 != 0:\n",
    "                raise ValueError(\"Invalid CSR matrix. Row %d contains %d numbers.\" % (i, len(p)))\n",
    "            nnz += len(p)/2\n",
    "            for j in xrange(0, len(p), 2): \n",
    "                cid = int(p[j]) - nidx\n",
    "                if cid+1 > ncols:\n",
    "                    ncols = cid+1\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sparse matrix ftype '%s'.\" % ftype)\n",
    "    val = np.zeros(nnz, dtype=np.float)\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.long)\n",
    "    n = 0 \n",
    "    for i in xrange(nrows):\n",
    "        p = lines[i].split()\n",
    "        for j in xrange(0, len(p), 2): \n",
    "            ind[n] = int(p[j]) - nidx\n",
    "            val[n] = float(p[j+1])\n",
    "            n += 1\n",
    "        ptr[i+1] = n \n",
    "    \n",
    "    assert(n == nnz)\n",
    "    \n",
    "    return csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"train.dat\"\n",
    "text_csr = csr_read(filename)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "idft = TfidfTransformer(norm=None)\n",
    "idfmatrix = idft.fit_transform(text_csr)\n",
    "denseidf = csr_matrix.todense(idfmatrix)\n",
    "normalizedwithoutReducing = normalize(idfmatrix, norm='l2')\n",
    "densenormalizedwithoutReducing = csr_matrix.todense(normalizedwithoutReducing)\n",
    "densenormalizedwithoutReducing = np.asarray(densenormalizedwithoutReducing)\n",
    "denseidf = np.asarray(denseidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k2_means(denseidf,densenormalizedwithoutReducing,centroid1=None,centroid2=None,iter=20):\n",
    "    if type(centroid1)!=np.ndarray or type(centroid2)!=np.ndarray:\n",
    "        #print \"here\"\n",
    "        cent1=0\n",
    "        cent2=0\n",
    "        num = denseidf.shape[0]-1\n",
    "        while (cent1==cent2):\n",
    "            cent1 = rm.randint(0, num)\n",
    "            cent2 = rm.randint(0, num)\n",
    "            #print normalizedwithoutReducing[cent1],cent2\n",
    "        centroid1 = np.array(densenormalizedwithoutReducing[cent1])\n",
    "        centroid2 = np.array(densenormalizedwithoutReducing[cent2])\n",
    "        centroidarray = np.append([centroid1],[centroid2], axis=0)\n",
    "        #print centroid1.shape\n",
    "        \n",
    "    else:\n",
    "        centroidarray = np.append([centroid1],[centroid2], axis=0)\n",
    "        #print centroidarray.shape\n",
    "        \n",
    "    centroidcosineArray = densenormalizedwithoutReducing.dot(centroidarray.T)\n",
    "    \n",
    "    i=0\n",
    "    cluster=[]\n",
    "    newcentroid1_points = 0\n",
    "    newcentroid2_points = 0\n",
    "    newcentroid1_sum = np.zeros(shape=[1,126355])\n",
    "    newcentroid2_sum = np.zeros(shape=[1,126355])\n",
    "    newcentroid1_mean = np.zeros(shape=[1,126355])\n",
    "    newcentroid2_mean = np.zeros(shape=[1,126355])\n",
    "    newcentroid1_mean_norm = np.zeros(shape=[1,126355])\n",
    "    newcentroid2_mean_norm = np.zeros(shape=[1,126355])\n",
    "    \n",
    "    for item in centroidcosineArray:\n",
    "        if item[0]>item[1]:\n",
    "            newcentroid1_points+=1\n",
    "            newcentroid1_sum = newcentroid1_sum+denseidf[i]\n",
    "            cluster.append(1)\n",
    "        else:\n",
    "            newcentroid2_points+=1\n",
    "            newcentroid2_sum = newcentroid2_sum+denseidf[i]\n",
    "            cluster.append(2)\n",
    "        i+=1\n",
    "    #print newcentroid1_points,newcentroid2_points\n",
    "    \n",
    "    newcentroid1_mean = newcentroid1_sum/newcentroid1_points\n",
    "    newcentroid2_mean = newcentroid2_sum/newcentroid2_points\n",
    "    \n",
    "    newcentroid1_mean_norm=normalize(newcentroid1_mean, norm='l2')\n",
    "    newcentroid2_mean_norm=normalize(newcentroid2_mean, norm='l2')\n",
    "    \n",
    "    #print newcentroid1_mean[0],centroid1\n",
    "    \n",
    "    comp1 = newcentroid1_mean_norm[0].dot(centroid1.T)\n",
    "    comp2 = newcentroid2_mean_norm[0].dot(centroid2.T)\n",
    "    \n",
    "    if (comp1>=0.99 and comp2>=0.99) or iter==0:\n",
    "        #print cluster\n",
    "        print iter,comp1,comp2,newcentroid1_points,newcentroid2_points\n",
    "        return cluster,newcentroid1_mean_norm,newcentroid2_mean_norm\n",
    "    else:\n",
    "        print iter,comp1,comp2,newcentroid1_points,newcentroid2_points\n",
    "        iter-=1\n",
    "        return k2_means(denseidf,densenormalizedwithoutReducing,newcentroid1_mean_norm[0],newcentroid2_mean_norm[0],iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.261358955569 0.301517934122 4447 4133\n",
      "19 0.991694263163 0.98656004728 4806 3774\n",
      "18 0.999413181198 0.999166869705 4897 3683\n"
     ]
    }
   ],
   "source": [
    "clusterresult,newcentroid1_mean_norm,newcentroid2_mean_norm = k2_means(denseidf,densenormalizedwithoutReducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 0\n",
      "4897 3683\n",
      "[ 0.20962075] [ 0.2084737]\n",
      "[array([ 0.20962075]), array([ 0.2084737])]\n",
      "2\n",
      "i 1\n",
      "here1\n",
      "20 0.154811250034 0.325837621049 1791 1892\n",
      "19 0.988481567384 0.961220708286 2368 1315\n",
      "18 0.999098302583 0.998634128341 2369 1314\n",
      "k 1\n",
      "2369 1314\n",
      "[ 0.1796831] [ 0.09005118]\n",
      "[array([ 0.20962075]), 1, array([ 0.1796831]), array([ 0.09005118])]\n",
      "4\n",
      "i 3\n",
      "here1\n",
      "20 0.214502095325 0.213621051563 303 1011\n",
      "19 0.975357830169 0.995460704135 392 922\n",
      "18 0.994123187203 0.998827366071 447 867\n",
      "k 2\n",
      "447 867\n",
      "[ 0.18769376] [ 0.22950258]\n",
      "[array([ 0.20962075]), 1, array([ 0.1796831]), 1, array([ 0.22950258]), array([ 0.18769376])]\n",
      "6\n",
      "i 2\n",
      "here1\n",
      "20 0.287871435544 0.26862717984 1177 1192\n",
      "19 0.990792832095 0.972881656417 1600 769\n",
      "18 0.99399725954 0.989406575995 1687 682\n",
      "17 0.999063761316 0.998426826345 1712 657\n",
      "k 3\n",
      "1712 657\n",
      "[ 0.23502152] [ 0.22755771]\n",
      "[array([ 0.20962075]), 1, 1, 1, array([ 0.22950258]), array([ 0.18769376]), array([ 0.23502152]), array([ 0.22755771])]\n",
      "8\n",
      "i 5\n",
      "here1\n",
      "20 0.302771022651 0.293965111346 213 234\n",
      "19 0.989293728672 0.988822365571 206 241\n",
      "18 0.997658653168 0.997195421159 211 236\n",
      "k 4\n",
      "211 236\n",
      "[ 0.21335488] [ 0.2050991]\n",
      "[array([ 0.20962075]), 1, 1, 1, array([ 0.22950258]), 1, array([ 0.23502152]), array([ 0.22755771]), array([ 0.21335488]), array([ 0.2050991])]\n",
      "10\n",
      "i 9\n",
      "here1\n",
      "20 0.375799039131 0.481894891982 131 105\n",
      "19 0.985032309611 0.988243000409 145 91\n",
      "18 0.996539584312 0.997369895466 145 91\n",
      "k 5\n",
      "145 91\n",
      "[ 0.2206992] [ 0.20407827]\n",
      "[array([ 0.20962075]), 1, 1, 1, array([ 0.22950258]), 1, array([ 0.23502152]), array([ 0.22755771]), array([ 0.21335488]), 1, array([ 0.2206992]), array([ 0.20407827])]\n",
      "12\n",
      "i 11\n",
      "here1\n",
      "20 0.314388108077 0.300073749881 12 79\n",
      "19 0.974309067873 0.999407508162 13 78\n",
      "18 1.0 1.0 13 78\n",
      "k 6\n",
      "13 78\n",
      "[ 0.14136573] [ 0.24493581]\n",
      "[array([ 0.20962075]), 1, 1, 1, array([ 0.22950258]), 1, array([ 0.23502152]), array([ 0.22755771]), array([ 0.21335488]), 1, array([ 0.2206992]), 1, array([ 0.24493581]), array([ 0.14136573])]\n",
      "14\n",
      "i 13\n",
      "here1\n",
      "20 0.713760049653 0.598298969537 5 8\n",
      "19 1.0 1.0 5 8\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "memoryrowsdict={}\n",
    "scores=[]\n",
    "flag=0\n",
    "odd=1\n",
    "even=0\n",
    "sent0=0\n",
    "sentlist=[]\n",
    "sentlist1 = defaultdict(list)\n",
    "positionofsent=0\n",
    "for kbisect in range(7):\n",
    "    print \"k\",kbisect\n",
    "    list1_for_memlist=[]\n",
    "    list2_for_memlist=[]\n",
    "    list2=[]\n",
    "    list22=[]\n",
    "    list1=[]\n",
    "    list11=[]\n",
    "    sum1=0\n",
    "    count1=0\n",
    "    sum2=0\n",
    "    count2=0\n",
    "    i=0\n",
    "    for items in clusterresult:\n",
    "            if items==1:\n",
    "                count1+=1\n",
    "                sum1 = sum1+(densenormalizedwithoutReducing[i].dot(newcentroid1_mean_norm.T))\n",
    "                list1.append(densenormalizedwithoutReducing[i])\n",
    "                list11.append(denseidf[i])\n",
    "                if kbisect==0:\n",
    "                    list1_for_memlist.append(i)\n",
    "                else:\n",
    "                    if flag==1:\n",
    "                        list1_for_memlist.append(memoryrowsdict[positionofsent][3][i])\n",
    "                    else:\n",
    "                        list1_for_memlist.append(memoryrowsdict[positionofsent][0][i])\n",
    "\n",
    "            else:\n",
    "                count2+=1\n",
    "                sum2 = sum2+densenormalizedwithoutReducing[i].dot(newcentroid2_mean_norm.T)\n",
    "                list2.append(densenormalizedwithoutReducing[i])\n",
    "                list22.append(denseidf[i])\n",
    "                if kbisect==0:\n",
    "                    list2_for_memlist.append(i)\n",
    "                else:\n",
    "                    if flag==1:\n",
    "                        list2_for_memlist.append(memoryrowsdict[positionofsent][3][i])\n",
    "                    else:\n",
    "                        list2_for_memlist.append(memoryrowsdict[positionofsent][0][i])\n",
    "            i+=1\n",
    "    print len(list1_for_memlist),len(list2_for_memlist)\n",
    "    avg1 = sum1/count1\n",
    "    avg2 = sum2/count2\n",
    "    print avg1,avg2\n",
    "    if avg1<avg2:\n",
    "        scores.append(avg2)\n",
    "        scores.append(avg1)\n",
    "        memoryrowsdict[kbisect]=[list2_for_memlist,list22,list2,list1_for_memlist,list11,list1]\n",
    "    else:\n",
    "        scores.append(avg1)\n",
    "        scores.append(avg2)\n",
    "        memoryrowsdict[kbisect]=[list1_for_memlist,list11,list1,list2_for_memlist,list22,list2]\n",
    "    index_min = min(xrange(len(scores)), key=scores.__getitem__)\n",
    "    print scores\n",
    "    print len(scores)\n",
    "    print \"i\",index_min\n",
    "    QR = divmod(index_min,2)\n",
    "    positionofsent=QR[0]\n",
    "    flag=QR[1]\n",
    "    scores[index_min]=1\n",
    "    sentlist1[positionofsent].append(flag)\n",
    "    if flag==1:\n",
    "        a=np.asarray(memoryrowsdict[positionofsent][4])\n",
    "        b=np.asarray(memoryrowsdict[positionofsent][5])\n",
    "    else:\n",
    "        a=np.asarray(memoryrowsdict[positionofsent][1])\n",
    "        b=np.asarray(memoryrowsdict[positionofsent][2])\n",
    "    print \"here1\"\n",
    "    clusterresult,newcentroid1_mean_norm,newcentroid2_mean_norm = k2_means(a,b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "defaultdict(<type 'list'>, {0: [1], 1: [1, 0], 2: [1], 4: [1], 5: [1], 6: [1]})\n"
     ]
    }
   ],
   "source": [
    "print len(memoryrowsdict)\n",
    "print sentlist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-d51236311209>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-d51236311209>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    if len(sentlist1[clus])==1\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "clusters_7=[]\n",
    "count_7 = 1\n",
    "for clus in range(7):\n",
    "    if clus in sentlist1.keys():\n",
    "        if len(sentlist1[clus])==1:\n",
    "                if sentlist1[clus][0]==1:\n",
    "                    clusters_7.append(memoryrowsdict[clus][0])\n",
    "                else:\n",
    "                    clusters_7.append(memoryrowsdict[clus][3])\n",
    "    else:\n",
    "        clusters_7.append(memoryrowsdict[clus][0])\n",
    "        clusters_7.append(memoryrowsdict[clus][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(clusters_7)\n",
    "clusterlabel=1\n",
    "final_list=[]\n",
    "for item in clusters_7:\n",
    "    for i in item:\n",
    "          final_list.append((clusterlabel,i))  \n",
    "    clusterlabel+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_by_second = sorted(final_list, key=lambda tup: tup[1])\n",
    "print sorted_by_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('format.dat', 'w')\n",
    "for item in sorted_by_second:\n",
    "    f.write(str(item[0])+'\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
