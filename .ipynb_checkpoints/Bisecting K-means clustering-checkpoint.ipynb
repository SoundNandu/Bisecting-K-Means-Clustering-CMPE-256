{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import random as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csr_read(fname, ftype=\"csr\", nidx=1):\n",
    "    r\"\"\" \n",
    "        Read CSR matrix from a text file. \n",
    "        \n",
    "        \\param fname File name for CSR/CLU matrix\n",
    "        \\param ftype Input format. Acceptable formats are:\n",
    "            - csr - Compressed sparse row\n",
    "            - clu - Cluto format, i.e., CSR + header row with \"nrows ncols nnz\"\n",
    "        \\param nidx Indexing type in CSR file. What does numbering of feature IDs start with?\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    if ftype == \"clu\":\n",
    "        p = lines[0].split()\n",
    "        nrows = int(p[0])\n",
    "        ncols = int(p[1])\n",
    "        nnz = long(p[2])\n",
    "        lines = lines[1:]\n",
    "        assert(len(lines) == nrows)\n",
    "    elif ftype == \"csr\":\n",
    "        nrows = len(lines)\n",
    "        ncols = 0 \n",
    "        nnz = 0 \n",
    "        for i in xrange(nrows):\n",
    "            p = lines[i].split()\n",
    "            if len(p) % 2 != 0:\n",
    "                raise ValueError(\"Invalid CSR matrix. Row %d contains %d numbers.\" % (i, len(p)))\n",
    "            nnz += len(p)/2\n",
    "            for j in xrange(0, len(p), 2): \n",
    "                cid = int(p[j]) - nidx\n",
    "                if cid+1 > ncols:\n",
    "                    ncols = cid+1\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sparse matrix ftype '%s'.\" % ftype)\n",
    "    val = np.zeros(nnz, dtype=np.float)\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.long)\n",
    "    n = 0 \n",
    "    for i in xrange(nrows):\n",
    "        p = lines[i].split()\n",
    "        for j in xrange(0, len(p), 2): \n",
    "            ind[n] = int(p[j]) - nidx\n",
    "            val[n] = float(p[j+1])\n",
    "            n += 1\n",
    "        ptr[i+1] = n \n",
    "    \n",
    "    assert(n == nnz)\n",
    "    \n",
    "    return csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"train.dat\"\n",
    "text_csr = csr_read(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dense_matrix = csr_matrix.todense(text_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print dense_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "idft = TfidfTransformer(norm=None)\n",
    "idfmatrix = idft.fit_transform(text_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denseidf = csr_matrix.todense(idfmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8580, 126355)\n"
     ]
    }
   ],
   "source": [
    "print denseidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import TruncatedSVD\n",
    "#svd = TruncatedSVD(n_components=4000)\n",
    "#reducedm = svd.fit_transform(idfmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(svd.explained_variance_ratio_)\n",
    "#print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib\n",
    "#fileObject = open('../pickle/idfmatrix.pickle','wb')\n",
    "#joblib.dump(idfmatrix, fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read code\n",
    "#fileObject = open('../pickle/idfmatrix.pickle','rb')\n",
    "#idfmatrix = joblib.load(fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib\n",
    "#fileObject = open('../pickle/actualreducedMwithoutnormalisation.pickle','wb')\n",
    "#joblib.dump(reducedm, fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#readcode\n",
    "#fileObject = open('../pickle/aactualreducedMwithoutnormalisation.pickle','rb')\n",
    "#reducedm = joblib.load(fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "#normalizedReduced=normalize(reducedm, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizedwithoutReducing = normalize(idfmatrix, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenormalizedwithoutReducing = csr_matrix.todense(normalizedwithoutReducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8580, 126355)\n"
     ]
    }
   ],
   "source": [
    "print densenormalizedwithoutReducing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenormalizedwithoutReducing = np.asarray(densenormalizedwithoutReducing)\n",
    "denseidf = np.asarray(denseidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type (densenormalizedwithoutReducing)\n",
    "print type (denseidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print densenormalizedwithoutReducing[0]\n",
    "print denseidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k2_means(denseidf,densenormalizedwithoutReducing,centroid1=None,centroid2=None,iter=20):\n",
    "    if type(centroid1)!=np.ndarray or type(centroid2)!=np.ndarray:\n",
    "        #print \"here\"\n",
    "        cent1=0\n",
    "        cent2=0\n",
    "        num = denseidf.shape[0]-1\n",
    "        while (cent1==cent2):\n",
    "            cent1 = rm.randint(0, num)\n",
    "            cent2 = rm.randint(0, num)\n",
    "            #print normalizedwithoutReducing[cent1],cent2\n",
    "        centroid1 = np.array(densenormalizedwithoutReducing[cent1])\n",
    "        centroid2 = np.array(densenormalizedwithoutReducing[cent2])\n",
    "        centroidarray = np.append([centroid1],[centroid2], axis=0)\n",
    "        #print centroid1.shape\n",
    "        \n",
    "    else:\n",
    "        centroidarray = np.append([centroid1],[centroid2], axis=0)\n",
    "        #print centroidarray.shape\n",
    "        \n",
    "    centroidcosineArray = densenormalizedwithoutReducing.dot(centroidarray.T)\n",
    "    \n",
    "    i=0\n",
    "    cluster=[]\n",
    "    newcentroid1_points = 0\n",
    "    newcentroid2_points = 0\n",
    "    newcentroid1_sum = np.zeros(shape=[1,126355])\n",
    "    newcentroid2_sum = np.zeros(shape=[1,126355])\n",
    "    newcentroid1_mean = np.zeros(shape=[1,126355])\n",
    "    newcentroid2_mean = np.zeros(shape=[1,126355])\n",
    "    newcentroid1_mean_norm = np.zeros(shape=[1,126355])\n",
    "    newcentroid2_mean_norm = np.zeros(shape=[1,126355])\n",
    "    \n",
    "    for item in centroidcosineArray:\n",
    "        if item[0]>item[1]:\n",
    "            newcentroid1_points+=1\n",
    "            newcentroid1_sum = newcentroid1_sum+denseidf[i]\n",
    "            cluster.append(1)\n",
    "        else:\n",
    "            newcentroid2_points+=1\n",
    "            newcentroid2_sum = newcentroid2_sum+denseidf[i]\n",
    "            cluster.append(2)\n",
    "        i+=1\n",
    "    #print newcentroid1_points,newcentroid2_points\n",
    "    \n",
    "    newcentroid1_mean = newcentroid1_sum/newcentroid1_points\n",
    "    newcentroid2_mean = newcentroid2_sum/newcentroid2_points\n",
    "    \n",
    "    newcentroid1_mean_norm=normalize(newcentroid1_mean, norm='l2')\n",
    "    newcentroid2_mean_norm=normalize(newcentroid2_mean, norm='l2')\n",
    "    \n",
    "    #print newcentroid1_mean[0],centroid1\n",
    "    \n",
    "    comp1 = newcentroid1_mean_norm[0].dot(centroid1.T)\n",
    "    comp2 = newcentroid2_mean_norm[0].dot(centroid2.T)\n",
    "    \n",
    "    if (comp1>=0.99 and comp2>=0.99) or iter==0:\n",
    "        #print cluster\n",
    "        print iter,comp1,comp2,newcentroid1_points,newcentroid2_points\n",
    "        return cluster,newcentroid1_mean_norm,newcentroid2_mean_norm\n",
    "    else:\n",
    "        print iter,comp1,comp2,newcentroid1_points,newcentroid2_points\n",
    "        iter-=1\n",
    "        return k2_means(denseidf,densenormalizedwithoutReducing,newcentroid1_mean_norm[0],newcentroid2_mean_norm[0],iter)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.184268344012 0.330019064707 4012 4568\n",
      "19 0.976912398121 0.98243339514 3990 4590\n",
      "18 0.995952095506 0.997984931352 3614 4966\n"
     ]
    }
   ],
   "source": [
    "clusterresult,newcentroid1_mean_norm,newcentroid2_mean_norm = k2_means(denseidf,densenormalizedwithoutReducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print densenormalizedwithoutReducing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 0\n",
      "3614 4966\n",
      "[ 0.23551023] [ 0.20385361]\n",
      "[array([ 0.23551023])]\n",
      "1\n",
      "i 0\n",
      "here3\n",
      "20 0.231810633505 0.259862180527 3522 1444\n",
      "19 0.972535364845 0.964279168022 2669 2297\n",
      "18 0.990715709092 0.992057088227 2308 2658\n",
      "k 1\n",
      "2308 2658\n",
      "[ 0.13088851] [ 0.14586426]\n",
      "[array([ 0.23551023]), array([ 0.14586426])]\n",
      "2\n",
      "i 1\n",
      "here1\n",
      "20 0.120862281866 0.175383113218 1664 644\n",
      "19 0.983320934 0.952572366666 1374 934\n",
      "18 0.996713150486 0.992758704829 1251 1057\n",
      "k 2\n",
      "1251 1057\n",
      "[ 0.24410129] [ 0.20026022]\n",
      "[array([ 0.23551023]), 1, array([ 0.24410129])]\n",
      "3\n",
      "i 0\n",
      "here4\n",
      "20 0.21953895066 0.175238964856 3307 307\n",
      "19 0.994121470234 0.901897655482 2985 629\n",
      "18 0.999270126286 0.985462692784 2920 694\n",
      "17 0.999323695388 0.990329135688 2797 817\n",
      "k 3\n",
      "2797 817\n",
      "[ 0.24935091] [ 0.15274675]\n",
      "[1, 1, array([ 0.24410129]), array([ 0.24935091])]\n",
      "4\n",
      "i 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-0e0a0a25b662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_min\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msentlist1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositionofsent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0mflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0msentlist1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositionofsent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "memoryrowsdict={}\n",
    "scores=[]\n",
    "flag=0\n",
    "odd=1\n",
    "even=0\n",
    "sent0=0\n",
    "sentlist=[]\n",
    "sentlist1 = defaultdict(list)\n",
    "positionofsent=0\n",
    "for kbisect in range(7):\n",
    "    print \"k\",kbisect\n",
    "    list1_for_memlist=[]\n",
    "    list2_for_memlist=[]\n",
    "    list2=[]\n",
    "    list22=[]\n",
    "    list1=[]\n",
    "    list11=[]\n",
    "    sum1=0\n",
    "    count1=0\n",
    "    sum2=0\n",
    "    count2=0\n",
    "    i=0\n",
    "    for items in clusterresult:\n",
    "            if items==1:\n",
    "                count1+=1\n",
    "                sum1 = sum1+(densenormalizedwithoutReducing[i].dot(newcentroid1_mean_norm.T))\n",
    "                list1.append(densenormalizedwithoutReducing[i])\n",
    "                list11.append(denseidf[i])\n",
    "                if kbisect==0:\n",
    "                    list1_for_memlist.append(i)\n",
    "                else:\n",
    "                    if flag==1:\n",
    "                        list1_for_memlist.append(memoryrowsdict[positionofsent][0][i])\n",
    "                    else:\n",
    "                        list1_for_memlist.append(memoryrowsdict[positionofsent][3][i])\n",
    "\n",
    "            else:\n",
    "                count2+=1\n",
    "                sum2 = sum2+densenormalizedwithoutReducing[i].dot(newcentroid2_mean_norm.T)\n",
    "                list2.append(densenormalizedwithoutReducing[i])\n",
    "                list22.append(denseidf[i])\n",
    "                if kbisect==0:\n",
    "                    list2_for_memlist.append(i)\n",
    "                else:\n",
    "                    if flag==1:\n",
    "                        list2_for_memlist.append(memoryrowsdict[positionofsent][0][i])\n",
    "                    else:\n",
    "                        list2_for_memlist.append(memoryrowsdict[positionofsent][3][i])\n",
    "            i+=1\n",
    "    print len(list1_for_memlist),len(list2_for_memlist)\n",
    "    avg1 = sum1/count1\n",
    "    avg2 = sum2/count2\n",
    "    print avg1,avg2\n",
    "    memoryrowsdict[kbisect]=[list2_for_memlist,list22,list2,list1_for_memlist,list11,list1]\n",
    "    #print memoryrowsdict[0][0][0],memoryrowsdict[0][1][0],memoryrowsdict[0][2][0],memoryrowsdict[0][3][0],memoryrowsdict[0][4][0],memoryrowsdict[0][5][0]\n",
    "    if avg1<avg2:\n",
    "        scores.append(avg2)\n",
    "        index_min = min(xrange(len(scores)), key=scores.__getitem__)\n",
    "        print scores\n",
    "        print len(scores)\n",
    "        print \"i\",index_min\n",
    "        positionofsent=index_min\n",
    "        if(index_min+1)==len(scores):\n",
    "            flag=0\n",
    "            if kbisect!=0:\n",
    "                scores[index_min]=1\n",
    "            else:\n",
    "                sent0=0\n",
    "            sentlist1[positionofsent].append(flag)\n",
    "            sentlist.append(odd)\n",
    "            a=np.asarray(memoryrowsdict[index_min][4])\n",
    "            b=np.asarray(memoryrowsdict[index_min][5])\n",
    "            #print a.shape,b.shape\n",
    "            #print a\n",
    "            print \"here1\"\n",
    "            clusterresult,newcentroid1_mean_norm,newcentroid2_mean_norm = k2_means(a,b)\n",
    "            #print clusterresult\n",
    "            odd+=2\n",
    "                        \n",
    "        else:\n",
    "            scores[index_min]=1\n",
    "            sentlist.append(even)\n",
    "            flag=1\n",
    "            sentlist1[positionofsent].append(flag)\n",
    "            if sentlist1[positionofsent][0]==0:\n",
    "                flag=1\n",
    "                sentlist1[positionofsent].append(flag)\n",
    "                a=np.asarray(memoryrowsdict[index_min][1])\n",
    "                b=np.asarray(memoryrowsdict[index_min][2])\n",
    "            else:\n",
    "                flag=0\n",
    "                sentlist1[positionofsent].append(flag)\n",
    "                a=np.asarray(memoryrowsdict[index_min][4])\n",
    "                b=np.asarray(memoryrowsdict[index_min][5])\n",
    "            #print a.shape,b.shape\n",
    "            #print a,b\n",
    "            print \"here2\"\n",
    "            clusterresult,newcentroid1_mean_norm,newcentroid2_mean_norm = k2_means(a,b)\n",
    "            #print clusterresult\n",
    "            even+=2\n",
    "                        \n",
    "    else:\n",
    "        scores.append(avg1)\n",
    "        index_min = min(xrange(len(scores)), key=scores.__getitem__)\n",
    "        positionofsent=index_min\n",
    "        print scores\n",
    "        print len(scores)\n",
    "        print \"i\",index_min\n",
    "        if(index_min+1)==len(scores):\n",
    "            flag=1\n",
    "            if kbisect!=0:\n",
    "                scores[index_min]=1\n",
    "            else:\n",
    "                 sent0 = 1\n",
    "            sentlist1[positionofsent].append(flag)\n",
    "            sentlist.append(even)\n",
    "            a=np.asarray(memoryrowsdict[index_min][1])\n",
    "            b=np.asarray(memoryrowsdict[index_min][2])\n",
    "            #print a.shape,b.shape\n",
    "            #print a,b\n",
    "            print \"here3\"\n",
    "            clusterresult,newcentroid1_mean_norm,newcentroid2_mean_norm = k2_means(a,b)\n",
    "            #print clusterresult\n",
    "            even+=2\n",
    "                        \n",
    "        else:\n",
    "            flag=0\n",
    "            sentlist1[positionofsent].append(flag)\n",
    "            scores[index_min]=1\n",
    "            if sentlist1[positionofsent][0]==0:\n",
    "                flag=1\n",
    "                sentlist1[positionofsent].append(flag)\n",
    "                a=np.asarray(memoryrowsdict[index_min][1])\n",
    "                b=np.asarray(memoryrowsdict[index_min][2])\n",
    "            else:\n",
    "                flag=0\n",
    "                sentlist1[positionofsent].append(flag)\n",
    "                a=np.asarray(memoryrowsdict[index_min][4])\n",
    "                b=np.asarray(memoryrowsdict[index_min][5])\n",
    "            #print a.shape,b.shape\n",
    "            #print a,b\n",
    "            print \"here4\"\n",
    "            clusterresult,newcentroid1_mean_norm,newcentroid2_mean_norm = k2_means(a,b)\n",
    "            #print clusterresult\n",
    "            odd+=2\n",
    "                        \n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print len(memoryrowsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'list'>, {0: [1, 0], 1: [0], 2: []})\n"
     ]
    }
   ],
   "source": [
    "print sentlist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3444\n",
      "1544\n",
      "1152\n",
      "874\n",
      "121\n",
      "64\n",
      "57\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-3babbdbea87e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mclusters_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryrowsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mclusters_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryrowsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryrowsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "clusters_7=[]\n",
    "count_7 = 1\n",
    "for clus in range(1,7):\n",
    "    if clus in sentlist1.keys():\n",
    "        #if clus!=0:\n",
    "        if sentlist1[clus]==1:\n",
    "            clusters_7.append(memoryrowsdict[clus][3])\n",
    "            print len((memoryrowsdict[clus][3]))\n",
    "        else:\n",
    "            clusters_7.append(memoryrowsdict[clus][0])\n",
    "            print len((memoryrowsdict[clus][0]))\n",
    "        #count_7+=1\n",
    "            #if count_7==8:\n",
    "                #break\n",
    "    else:\n",
    "        '''if clus==0 and sent==1:\n",
    "            clusters_7.append(memoryrowsdict[clus][3])\n",
    "            print len((memoryrowsdict[clus][3]))\n",
    "            count_7+=1\n",
    "            if count_7==8:\n",
    "                break\n",
    "        elif clus==0 and sent==0: \n",
    "            clusters_7.append(memoryrowsdict[clus][0])\n",
    "            print len((memoryrowsdict[clus][0]))\n",
    "            count_7+=1\n",
    "            if count_7==8:\n",
    "                break\n",
    "        else:'''\n",
    "        clusters_7.append(memoryrowsdict[clus][0])\n",
    "        print len((memoryrowsdict[clus][0]))\n",
    "        #count_7+=1\n",
    "        #if count_7==8:\n",
    "            #break\n",
    "        clusters_7.append(memoryrowsdict[clus][3])\n",
    "        print len((memoryrowsdict[clus][3]))\n",
    "            #count_7+=1\n",
    "            #if count_7==8:\n",
    "                #break\n",
    "                \n",
    "clusters_7.append[(memoryrowsdict[6][3])]\n",
    "clusters_7.append[(memoryrowsdict[6][0])]\n",
    "print len((memoryrowsdict[6][3]))\n",
    "print len((memoryrowsdict[6][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-983d4afd8580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclusters_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryrowsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclusters_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryrowsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryrowsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryrowsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print len(clusters_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterlabel=1\n",
    "final_list=[]\n",
    "for item in clusters_7:\n",
    "    for i in item:\n",
    "          final_list.append((clusterlabel,i))  \n",
    "    clusterlabel+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10600\n"
     ]
    }
   ],
   "source": [
    "print len(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_by_second = sorted(final_list, key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print sorted_by_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sorted_by_second\n",
    "del final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
